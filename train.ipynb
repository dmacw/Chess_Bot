{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn # type: ignore\n",
    "import torch.optim as optim # type: ignore\n",
    "from torch.utils.data import DataLoader # type: ignore\n",
    "from chess import pgn # type: ignore\n",
    "from tqdm import tqdm # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "\n",
    "def load_pgn(file_path):\n",
    "    games = []\n",
    "    with open(file_path, 'r') as pgn_file:\n",
    "        while True:\n",
    "            game = pgn.read_game(pgn_file)\n",
    "            if game is None:\n",
    "                break\n",
    "            games.append(game)\n",
    "    return games\n",
    "\n",
    "files = [file for file in os.listdir(\"../../data/pgn\") if file.endswith(\".pgn\")]\n",
    "LIMIT_OF_FILES = min(len(files), 28)\n",
    "games = []\n",
    "i = 1\n",
    "for file in tqdm(files):\n",
    "    games.extend(load_pgn(f\"../../data/pgn/{file}\"))\n",
    "    if i >= LIMIT_OF_FILES:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"GAMES PARSED: {len(games)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert Data into Tensors\n",
    "\n",
    "from auxiliary_func import create_input_for_nn, encode_moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_input_for_nn(games)\n",
    "\n",
    "print(f\"NUMBER OF SAMPLES: {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:2500000]\n",
    "y = y[0:2500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, move_to_int = encode_moves(y)\n",
    "num_classes = len(move_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"before: {X.shape}\")\n",
    "X = np.transpose(X, (0, 3, 1, 2))  # Change shape from [num_samples, 8, 8, 13] to [num_samples, 8, 13, 8]\n",
    "print(f\"after: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary Actions\n",
    "\n",
    "from dataset import ChessDataset\n",
    "from model import ChessModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataset and DataLoader\n",
    "dataset = ChessDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Model Initialization\n",
    "model = ChessModel(num_classes=num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "\n",
    "# Training Loop with Verbose Output\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)  # Raw logits\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    minutes: int = int(epoch_time // 60)\n",
    "    seconds: int = int(epoch_time) - minutes * 60\n",
    "    print(f'Epoch {epoch + 1 + 50}/{num_epochs + 1 + 50}, Loss: {running_loss / len(dataloader):.4f}, Time: {minutes}m{seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Model and Mappings\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"../../models/TORCH_100EPOCHS.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../../models/heavy_move_to_int\", \"wb\") as file:\n",
    "    pickle.dump(move_to_int, file)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
